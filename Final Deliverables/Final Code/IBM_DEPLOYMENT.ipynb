{"cells": [{"metadata": {"id": "GFVibDchMNM4"}, "cell_type": "markdown", "source": "**Importing Libraries**"}, {"metadata": {"id": "0mgoitetMMMQ"}, "cell_type": "code", "source": "import numpy as np #used for numerical analysis\nimport tensorflow #open source used for both ML and DL for computation\nimport matplotlib.pyplot as plt\nimport os\nimport torch\nfrom tensorflow import keras\nfrom tensorflow.keras.datasets import mnist #mnist dataser\nfrom tensorflow.keras.models import Sequential #it is a plain stack of Layers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras import layers #A Layer consists of a tensor - in tensor - out computation function\nfrom tensorflow.keras.layers import Dense , Flatten\n# Faltten - used fot flattening the input or change the dimension\n# Dense - Dense Layer is the regular deeply connected in \nfrom tensorflow.keras.layers import Conv2D , MaxPool2D , Dropout  # conv2d -Convolutional Layer\nfrom tensorflow.keras.optimizers import Adam   #optimizer\nfrom keras.utils import np_utils #used for one - hot encoding", "execution_count": 41, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 40, "outputs": [{"output_type": "execute_result", "execution_count": 40, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ho5eco8Qj34k", "outputId": "eb99b80c-cbf1-4dd3-c6f9-1de5f8e3fd97"}, "cell_type": "code", "source": "from google.colab import drive\ndrive.mount('/content/drive')", "execution_count": 42, "outputs": [{"output_type": "error", "ename": "ModuleNotFoundError", "evalue": "No module named 'google.colab'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_164/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "B8RYupuLkBcA", "outputId": "8e1d0088-4a78-4c65-d0d0-d11cc721f264"}, "cell_type": "code", "source": "%ls /content", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "ls: cannot access '/content': No such file or directory\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": null, "outputs": []}, {"metadata": {"id": "z_-CfTEGMUlJ"}, "cell_type": "markdown", "source": "**Getting Data and Pre Process it**"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "W5Q16pbzMaox", "outputId": "3688e721-d65f-41bb-8810-90cb9c6e2e06"}, "cell_type": "code", "source": "(x_train , y_train),(x_test , y_test) = mnist.load_data() #x contains the images and y has its label, like if its the image of 1 then its label will be 1.\nx_train.shape , y_train.shape , x_test.shape , y_test.shape", "execution_count": 43, "outputs": [{"output_type": "execute_result", "execution_count": 43, "data": {"text/plain": "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"}, "metadata": {}}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 283}, "id": "WdCLD7_ZMdf0", "outputId": "ea921456-a6ed-4c7e-ddf9-b7b00f356fc6"}, "cell_type": "code", "source": "plt.imshow(x_train[5] , cmap = \"binary\")", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "<matplotlib.image.AxesImage at 0x7fd680098250>"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "<Figure size 432x288 with 1 Axes>", "image/png": "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\n"}, "metadata": {"needs_background": "light"}}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "qpo2PRDEMjLa", "outputId": "c3af6b1f-b19a-4482-dc0e-7e37d2b464de"}, "cell_type": "code", "source": "# Pre Process the images\n\n#Normalizing the imaeges to [0,1] range\nx_train = x_train.astype(np.float32)/255\nx_test = x_test.astype(np.float32)/255\n\n#expand the dimensions of the images to (28,28,1)[we use 1 here bcoz the image we take is binary]\nx_train = np.expand_dims(x_train,-1)\nx_test = np.expand_dims(x_test,-1)\nx_train.shape , x_test.shape", "execution_count": 44, "outputs": [{"output_type": "execute_result", "execution_count": 44, "data": {"text/plain": "((60000, 28, 28, 1), (10000, 28, 28, 1))"}, "metadata": {}}]}, {"metadata": {"id": "tioU7ufuNKw0"}, "cell_type": "code", "source": "#one hot encoding\n#[1 will be prensent in the array if that particular image has that value.ex. in 2nd row the second image has value 0 so 1 is present in 0th position]\n\ny_train = keras.utils.to_categorical(y_train)\ny_test = keras.utils.to_categorical(y_test)", "execution_count": 45, "outputs": []}, {"metadata": {"id": "zEEtct8EQOzx"}, "cell_type": "markdown", "source": "**Model Building**"}, {"metadata": {"id": "eyw5jXxLPyrf"}, "cell_type": "code", "source": "model = Sequential() #INITIALIZE\n\nmodel.add(Conv2D(32, (3,3), input_shape = (28,28,1) , activation = \"relu\"))#(3,3) is the kernal size\nmodel.add(MaxPool2D((2,2))) # (2,2) isthe pool size\n\nmodel.add(Conv2D(64, (3,3) , activation = \"relu\"))#(3,3) is the kernal size\nmodel.add(MaxPool2D((2,2))) # (2,2) isthe pool size\n\nmodel.add(Flatten())\n\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(10, activation = \"softmax\"))#dense is used for classification and 10(numbers from 0-9) is the num of layers.", "execution_count": 46, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "hGW1JW_QUlzY", "outputId": "b8650130-9e59-408c-c88e-648cebf79067"}, "cell_type": "code", "source": "input_shape = (28,28,1)\nmodel.build(input_shape)\nmodel.summary()", "execution_count": 47, "outputs": [{"output_type": "stream", "text": "Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n 2D)                                                             \n                                                                 \n conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n                                                                 \n max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n 2D)                                                             \n                                                                 \n flatten_1 (Flatten)         (None, 1600)              0         \n                                                                 \n dropout_1 (Dropout)         (None, 1600)              0         \n                                                                 \n dense_1 (Dense)             (None, 10)                16010     \n                                                                 \n=================================================================\nTotal params: 34,826\nTrainable params: 34,826\nNon-trainable params: 0\n_________________________________________________________________\n", "name": "stdout"}]}, {"metadata": {"id": "WaqsYw_QUpPZ"}, "cell_type": "code", "source": "model.compile(optimizer = 'adam', loss = keras.losses.categorical_crossentropy , metrics = ['accuracy'])", "execution_count": 48, "outputs": []}, {"metadata": {"id": "ktZdOgsPU8FP"}, "cell_type": "code", "source": "#callbacks\n\n#EarlyStopping\n\nes = EarlyStopping(monitor = \"val_acc\", min_delta= 0.01, patience = 5 , verbose= 1)\n \n #Model Checpoint\n\nmc = ModelCheckpoint('./bestmodel.h5' , monitor = \"val_acc\", verbose = 1, save_best_only = True)\n \ncb = [es,mc] ", "execution_count": 49, "outputs": []}, {"metadata": {"id": "NbtRuk_iWVIO"}, "cell_type": "markdown", "source": "**Model Training**"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "4U-wNRX8WbFu", "outputId": "cc7b026f-63c0-4956-de2c-c3f33b51fb9f"}, "cell_type": "code", "source": "his = model.fit(x_train,y_train, epochs = 50, validation_split = 0.3,callbacks = cb)", "execution_count": null, "outputs": [{"output_type": "stream", "text": "Epoch 1/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9983WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.0700 - val_accuracy: 0.9898\nEpoch 2/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0647 - val_accuracy: 0.9899\nEpoch 3/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9980WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 37s 28ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0553 - val_accuracy: 0.9911\nEpoch 4/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9983WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0590 - val_accuracy: 0.9911\nEpoch 5/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 37s 28ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0599 - val_accuracy: 0.9913\nEpoch 6/50\n1313/1313 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9984WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 0.0648 - val_accuracy: 0.9906\nEpoch 7/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9986WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0612 - val_accuracy: 0.9904\nEpoch 8/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0631 - val_accuracy: 0.9902\nEpoch 9/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0614 - val_accuracy: 0.9908\nEpoch 10/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9983WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0676 - val_accuracy: 0.9897\nEpoch 11/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9982WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0643 - val_accuracy: 0.9911\nEpoch 12/50\n1313/1313 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0639 - val_accuracy: 0.9899\nEpoch 13/50\n1313/1313 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0623 - val_accuracy: 0.9906\nEpoch 14/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9982WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 39s 29ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0700 - val_accuracy: 0.9903\nEpoch 15/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9985WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 39s 29ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0648 - val_accuracy: 0.9906\nEpoch 16/50\n1313/1313 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9982WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 39s 29ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0586 - val_accuracy: 0.9911\nEpoch 17/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0604 - val_accuracy: 0.9918\nEpoch 18/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0622 - val_accuracy: 0.9908\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch 19/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 37s 28ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0579 - val_accuracy: 0.9914\nEpoch 20/50\n1313/1313 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9983WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0574 - val_accuracy: 0.9915\nEpoch 21/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0612 - val_accuracy: 0.9916\nEpoch 22/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0628 - val_accuracy: 0.9914\nEpoch 23/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 39s 30ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0559 - val_accuracy: 0.9919\nEpoch 24/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0764 - val_accuracy: 0.9898\nEpoch 25/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9988WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0556 - val_accuracy: 0.9919\nEpoch 26/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0645 - val_accuracy: 0.9911\nEpoch 27/50\n1313/1313 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 39s 30ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0672 - val_accuracy: 0.9907\nEpoch 28/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0615 - val_accuracy: 0.9909\nEpoch 29/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0703 - val_accuracy: 0.9911\nEpoch 30/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0650 - val_accuracy: 0.9914\nEpoch 31/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 39s 30ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0711 - val_accuracy: 0.9907\nEpoch 32/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0569 - val_accuracy: 0.9917\nEpoch 33/50\n1313/1313 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0641 - val_accuracy: 0.9916\nEpoch 34/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0623 - val_accuracy: 0.9918\nEpoch 35/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9985WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0630 - val_accuracy: 0.9919\nEpoch 36/50\n1313/1313 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0765 - val_accuracy: 0.9906\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch 37/50\n1313/1313 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0667 - val_accuracy: 0.9909\nEpoch 38/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0736 - val_accuracy: 0.9893\nEpoch 39/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0612 - val_accuracy: 0.9911\nEpoch 40/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0699 - val_accuracy: 0.9902\nEpoch 41/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 37s 28ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0699 - val_accuracy: 0.9912\nEpoch 42/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0669 - val_accuracy: 0.9921\nEpoch 43/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9986WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 39s 30ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0656 - val_accuracy: 0.9908\nEpoch 44/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 37s 29ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0679 - val_accuracy: 0.9914\nEpoch 45/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0663 - val_accuracy: 0.9916\nEpoch 46/50\n1313/1313 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0648 - val_accuracy: 0.9916\nEpoch 47/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9988WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0721 - val_accuracy: 0.9914\nEpoch 48/50\n1312/1313 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0636 - val_accuracy: 0.9907\nEpoch 49/50\n1311/1313 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n1313/1313 [==============================] - 38s 29ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0674 - val_accuracy: 0.9911\nEpoch 50/50\n  40/1313 [..............................] - ETA: 33s - loss: 3.2699e-04 - accuracy: 1.0000", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "model.save(\"digitreg.h5\")", "execution_count": null, "outputs": []}, {"metadata": {"id": "qvKThu-8fONg"}, "cell_type": "code", "source": "#save the model\n\nmodel.save(\"digitreg.h5\")\nmodel_path = \"/content/drive/MyDrive/digitreg.h5\"\nmodel_s = keras.models.load_model( \"/content/digitreg.h5\")", "execution_count": 64, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!tar -zcvf handwritten-digit-recognition-model.tgz digitreg.h5", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "nCSaBajsuNsD", "outputId": "389cd351-2840-4c3f-cc55-c1f475b5e092"}, "cell_type": "code", "source": "#model evalutaion/ accuracy\n\nscore = model_s.evaluate(x_test, y_test)\nprint(f\"the model accuracy is {score[1]} \")\nprint(f\"the model loss is {score[0]} \")", "execution_count": 65, "outputs": [{"name": "stdout", "output_type": "stream", "text": "313/313 [==============================] - 4s 11ms/step - loss: 0.0397 - accuracy: 0.9926\nthe model accuracy is 0.9926000237464905 \nthe model loss is 0.03968239203095436 \n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# IBM Deployment"}, {"metadata": {}, "cell_type": "code", "source": "!pip install watson-machine-learning-client", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "Collecting watson-machine-learning-client\n  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 538 kB 13.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\nRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\nInstalling collected packages: watson-machine-learning-client\nSuccessfully installed watson-machine-learning-client-1.0.391\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\nwml_credentials = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\": \"ydsVJmqjGOQz-DPlKpo72hizlL3prSNkuQ1Jj2bjPoFR\"\n}\nclient = APIClient(wml_credentials)", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client", "execution_count": 21, "outputs": [{"output_type": "execute_result", "execution_count": 21, "data": {"text/plain": "<ibm_watson_machine_learning.client.APIClient at 0x7fd65c11c670>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "def guid_space_name(client,Newspace):\n    space = client.spaces.get_details()\n    return(next(item for item in space['resources'] if item['entity']['name']==Newspace)['metadata']['id'])", "execution_count": 31, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "space_uid = guid_space_name(client, 'Newspace')\nprint(\"SPACE UID \"+space_uid)", "execution_count": 32, "outputs": [{"output_type": "stream", "text": "SPACE UID 936dc63b-8437-4183-a109-b29cf7928a6e\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_uid)", "execution_count": 33, "outputs": [{"output_type": "execute_result", "execution_count": 33, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.software_specifications.list(200)", "execution_count": 34, "outputs": [{"output_type": "stream", "text": "-------------------------------  ------------------------------------  ----\nNAME                             ASSET_ID                              TYPE\ndefault_py3.6                    0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\nkernel-spark3.2-scala2.12        020d69ce-7ac1-5e68-ac1a-31189867356a  base\npytorch-onnx_1.3-py3.7-edt       069ea134-3346-5748-b513-49120e15d288  base\nscikit-learn_0.20-py3.6          09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\nspark-mllib_3.0-scala_2.12       09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\npytorch-onnx_rt22.1-py3.9        0b848dd4-e681-5599-be41-b5f6fccc6471  base\nai-function_0.1-py3.6            0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\nshiny-r3.6                       0e6e79df-875e-4f24-8ae9-62dcc2148306  base\ntensorflow_2.4-py3.7-horovod     1092590a-307d-563d-9b62-4eb7d64b3f22  base\npytorch_1.1-py3.6                10ac12d6-6b30-4ccd-8392-3e922c096a92  base\ntensorflow_1.15-py3.6-ddl        111e41b3-de2d-5422-a4d6-bf776828c4b7  base\nautoai-kb_rt22.2-py3.10          125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\nruntime-22.1-py3.9               12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\nscikit-learn_0.22-py3.6          154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\ndefault_r3.6                     1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\npytorch-onnx_1.3-py3.6           1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\nkernel-spark3.3-r3.6             1c9e5454-f216-59dd-a20e-474a5cdf5988  base\npytorch-onnx_rt22.1-py3.9-edt    1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\ntensorflow_2.1-py3.6             1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\nspark-mllib_3.2                  20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\ntensorflow_2.4-py3.8-horovod     217c16f6-178f-56bf-824a-b19f20564c49  base\nruntime-22.1-py3.9-cuda          26215f05-08c3-5a41-a1b0-da66306ce658  base\ndo_py3.8                         295addb5-9ef9-547e-9bf4-92ae3563e720  base\nautoai-ts_3.8-py3.8              2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\ntensorflow_1.15-py3.6            2b73a275-7cbf-420b-a912-eae7f436e0bc  base\nkernel-spark3.3-py3.9            2b7961e2-e3b1-5a8c-a491-482c8368839a  base\npytorch_1.2-py3.6                2c8ef57d-2687-4b7d-acce-01f94976dac1  base\nspark-mllib_2.3                  2e51f700-bca0-4b0d-88dc-5c6791338875  base\npytorch-onnx_1.1-py3.6-edt       32983cea-3f32-4400-8965-dde874a8d67e  base\nspark-mllib_3.0-py37             36507ebe-8770-55ba-ab2a-eafe787600e9  base\nspark-mllib_2.4                  390d21f8-e58b-4fac-9c55-d7ceda621326  base\nautoai-ts_rt22.2-py3.10          396b2e83-0953-5b86-9a55-7ce1628a406f  base\nxgboost_0.82-py3.6               39e31acd-5f30-41dc-ae44-60233c80306e  base\npytorch-onnx_1.2-py3.6-edt       40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\npytorch-onnx_rt22.2-py3.10       40e73f55-783a-5535-b3fa-0c8b94291431  base\ndefault_r36py38                  41c247d3-45f8-5a71-b065-8580229facf0  base\nautoai-ts_rt22.1-py3.9           4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\nautoai-obm_3.0                   42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\npmml-3.0_4.3                     493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\nspark-mllib_2.4-r_3.6            49403dff-92e9-4c87-a3d7-a42d0021c095  base\nxgboost_0.90-py3.6               4ff8d6c2-1343-4c18-85e1-689c965304d3  base\npytorch-onnx_1.1-py3.6           50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\nautoai-ts_3.9-py3.8              52c57136-80fa-572e-8728-a5e7cbb42cde  base\nspark-mllib_2.4-scala_2.11       55a70f99-7320-4be5-9fb9-9edb5a443af5  base\nspark-mllib_3.0                  5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\nautoai-obm_2.0                   5c2e37fa-80b8-5e77-840f-d912469614ee  base\nspss-modeler_18.1                5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\ncuda-py3.8                       5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\nautoai-kb_3.1-py3.7              632d4b22-10aa-5180-88f0-f52dfb6444d7  base\npytorch-onnx_1.7-py3.8           634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\nspark-mllib_2.3-r_3.6            6586b9e3-ccd6-4f92-900f-0f8cb2bd6f0c  base\ntensorflow_2.4-py3.7             65e171d7-72d1-55d9-8ebb-f813d620c9bb  base\nspss-modeler_18.2                687eddc9-028a-4117-b9dd-e57b36f1efa5  base\npytorch-onnx_1.2-py3.6           692a6a4d-2c4d-45ff-a1ed-b167ee55469a  base\nspark-mllib_2.3-scala_2.11       7963efe5-bbec-417e-92cf-0574e21b4e8d  base\nspark-mllib_2.4-py37             7abc992b-b685-532b-a122-a396a3cdbaab  base\ncaffe_1.0-py3.6                  7bb3dbe2-da6e-4145-918d-b6d84aa93b6b  base\npytorch-onnx_1.7-py3.7           812c6631-42b7-5613-982b-02098e6c909c  base\ncuda-py3.6                       82c79ece-4d12-40e6-8787-a7b9e0f62770  base\ntensorflow_1.15-py3.6-horovod    8964680e-d5e4-5bb8-919b-8342c6c0dfd8  base\nhybrid_0.1                       8c1a58c6-62b5-4dc4-987a-df751c2756b6  base\npytorch-onnx_1.3-py3.7           8d5d8a87-a912-54cf-81ec-3914adaa988d  base\ncaffe-ibm_1.0-py3.6              8d863266-7927-4d1e-97d7-56a7f4c0a19b  base\nspss-modeler_17.1                902d0051-84bd-4af6-ab6b-8f6aa6fdeabb  base\ndo_12.10                         9100fd72-8159-4eb9-8a0b-a87e12eefa36  base\ndo_py3.7                         9447fa8b-2051-4d24-9eef-5acb0e3c59f8  base\nspark-mllib_3.0-r_3.6            94bb6052-c837-589d-83f1-f4142f219e32  base\ncuda-py3.7-opence                94e9652b-7f2d-59d5-ba5a-23a414ea488f  base\nnlp-py3.8                        96e60351-99d4-5a1c-9cc0-473ac1b5a864  base\ncuda-py3.7                       9a44990c-1aa1-4c7d-baf8-c4099011741c  base\nhybrid_0.2                       9b3f9040-9cee-4ead-8d7a-780600f542f7  base\nspark-mllib_3.0-py38             9f7a8fc1-4d3c-5e65-ab90-41fa8de2d418  base\nautoai-kb_3.3-py3.7              a545cca3-02df-5c61-9e88-998b09dc79af  base\nspark-mllib_3.0-py39             a6082a27-5acc-5163-b02c-6b96916eb5e0  base\nruntime-22.1-py3.9-do            a7e7dbf1-1d03-5544-994d-e5ec845ce99a  base\ndefault_py3.8                    ab9e1b80-f2ce-592c-a7d2-4f2344f77194  base\ntensorflow_rt22.1-py3.9          acd9c798-6974-5d2f-a657-ce06e986df4d  base\nkernel-spark3.2-py3.9            ad7033ee-794e-58cf-812e-a95f4b64b207  base\nautoai-obm_2.0 with Spark 3.0    af10f35f-69fa-5d66-9bf5-acb58434263a  base\ndefault_py3.7_opence             c2057dd4-f42c-5f77-a02f-72bdbd3282c9  base\ntensorflow_2.1-py3.7             c4032338-2a40-500a-beef-b01ab2667e27  base\ndo_py3.7_opence                  cc8f8976-b74a-551a-bb66-6377f8d865b4  base\nspark-mllib_3.3                  d11f2434-4fc7-58b7-8a62-755da64fdaf8  base\nautoai-kb_3.0-py3.6              d139f196-e04b-5d8b-9140-9a10ca1fa91a  base\nspark-mllib_3.0-py36             d82546d5-dd78-5fbb-9131-2ec309bc56ed  base\nautoai-kb_3.4-py3.8              da9b39c3-758c-5a4f-9cfd-457dd4d8c395  base\nkernel-spark3.2-r3.6             db2fe4d6-d641-5d05-9972-73c654c60e0a  base\nautoai-kb_rt22.1-py3.9           db6afe93-665f-5910-b117-d879897404d9  base\ntensorflow_rt22.1-py3.9-horovod  dda170cc-ca67-5da7-9b7a-cf84c6987fae  base\nautoai-ts_1.0-py3.7              deef04f0-0c42-5147-9711-89f9904299db  base\ntensorflow_2.1-py3.7-horovod     e384fce5-fdd1-53f8-bc71-11326c9c635f  base\ndefault_py3.7                    e4429883-c883-42b6-87a8-f419d64088cd  base\ndo_22.1                          e51999ba-6452-5f1f-8287-17228b88b652  base\nautoai-obm_3.2                   eae86aab-da30-5229-a6a6-1d0d4e368983  base\ntensorflow_rt22.2-py3.10         f65bd165-f057-55de-b5cb-f97cf2c0f393  base\ndo_20.1                          f686cdd9-7904-5f9d-a732-01b0d6b10dc5  base\npytorch-onnx_rt22.2-py3.10-edt   f8a05d07-e7cd-57bb-a10b-23f1d4b837ac  base\nscikit-learn_0.19-py3.6          f963fa9d-4bb7-5652-9c5d-8d9289ef6ad9  base\ntensorflow_2.4-py3.8             fe185c44-9a99-5425-986b-59bd1d2eda46  base\n-------------------------------  ------------------------------------  ----\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "software_space_uid=client.software_specifications.get_uid_by_name('tensorflow_rt22.1-py3.9')", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "software_space_uid", "execution_count": 39, "outputs": [{"output_type": "execute_result", "execution_count": 39, "data": {"text/plain": "'acd9c798-6974-5d2f-a657-ce06e986df4d'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model_details=client.repository.store_model(model='handwritten-digit-recognition-model.tgz',meta_props={\n    client.repository.ModelMetaNames.NAME:\"CNN Model Building\",\n    client.repository.ModelMetaNames.TYPE:'tensorflow_2.7,\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_space_uid\n})", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model_id=client.repository.get_model_id(model_details)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model_id", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client.repository.download(model_id, 'Handwrittendigitreg.tar.gb')", "execution_count": null, "outputs": []}], "metadata": {"colab": {"collapsed_sections": [], "provenance": []}, "kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "vscode": {"interpreter": {"hash": "1ebf68deec2cb05eb227d9a1d0724ea2a40027b1cc66a78b2ac101a209076037"}}}, "nbformat": 4, "nbformat_minor": 1}